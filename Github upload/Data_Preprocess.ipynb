{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from retinaface import RetinaFace\n",
    "from mtcnn import MTCNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_directory = ''  # 데이터셋 디렉토리 경로 설정\n",
    "dataset_path_json_save_path = \"" #Dataset에 대한 subject 정리 및 ground truth 정리 json 파일 저장 경로\n",
    "processed_numpy_save_path = '' #비디오 RGB 정보를 담은 numpy 저장 경로\n",
    "vital_video_list_path =  '' #최종 vital video dataset list \n",
    "processing_save_list_path = '",
    "device_printed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search DATASET Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_completed_subjects(subject_list, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(subject_list, f, indent=4)\n",
    "\n",
    "def load_completed_subjects(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_in_json(data, key, target_key='value'):\n",
    "    if isinstance(data, dict):\n",
    "        if data.get('parameter') == key:\n",
    "            return data.get(target_key)\n",
    "        for v in data.values():\n",
    "            result = find_value_in_json(v, key, target_key)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            result = find_value_in_json(item, key, target_key)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_videos_and_ground_truths(base_dir):\n",
    "    dataset = defaultdict(dict)\n",
    "    subject_index = 0\n",
    "    \n",
    "    # 모든 mp4 파일 탐색\n",
    "    mp4_files = glob.glob(os.path.join(base_dir, '**', '*.mp4'), recursive=True)\n",
    "    json_files = glob.glob(os.path.join(base_dir, '**', '*.json'), recursive=True)\n",
    "\n",
    "    # Subject 이름을 단순화하여 매핑\n",
    "    subject_map = {}\n",
    "\n",
    "    # mp4 파일과 json 파일을 매칭\n",
    "    for mp4_file in mp4_files:\n",
    "        # 파일명에서 기본 subject 이름 추출 (0a8ab78a2c1e44718a467c400e78a910_1.mp4 -> 0a8ab78a2c1e44718a467c400e78a910)\n",
    "        filename = os.path.basename(mp4_file)\n",
    "        base_name = filename.rsplit('_', 1)[0]\n",
    "        \n",
    "        # Subject 이름이 이미 매핑되어 있는지 확인\n",
    "        if base_name not in subject_map:\n",
    "            subject_map[base_name] = f\"subject{subject_index}\"\n",
    "            subject_index += 1\n",
    "            \n",
    "        subject_name = subject_map[base_name]\n",
    "        \n",
    "        # 해당 subject의 비디오 리스트에 추가\n",
    "        if \"video\" not in dataset[subject_name]:\n",
    "            dataset[subject_name][\"video\"] = []\n",
    "        dataset[subject_name][\"video\"].append(mp4_file)\n",
    "    \n",
    "    # 비디오 파일의 순서를 -1, -2로 정렬\n",
    "    for subject_name, data in dataset.items():\n",
    "        data[\"video\"].sort(key=lambda x: x.split('_')[-1])  # -1.mp4가 먼저 오도록 정렬\n",
    "    \n",
    "    # json 파일을 해당 subject와 연결\n",
    "    for json_file in json_files:\n",
    "        filename = os.path.basename(json_file)\n",
    "        base_name = filename.split('.')[0]\n",
    "        \n",
    "        if base_name in subject_map:\n",
    "            subject_name = subject_map[base_name]\n",
    "            dataset[subject_name][\"ground_truth\"] = json_file\n",
    "            \n",
    "            with open(dataset[subject_name][\"ground_truth\"], 'r') as file:\n",
    "                data = json.load(file)\n",
    "            bp_sys_value = find_value_in_json(data, 'bp_sys')\n",
    "            bp_dia_value = find_value_in_json(data,'bp_dia')\n",
    "            if bp_sys_value is not None and bp_dia_value is not None:\n",
    "                dataset[subject_name][\"BP\"] = {\"bp_sys\": bp_sys_value, \"bp_dia\": bp_dia_value}\n",
    "                \n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, path):\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = find_videos_and_ground_truths(dataset_base_directory)\n",
    "\n",
    "# print(file_path)\n",
    "a = 1\n",
    "path = \"subject\" + str(a)\n",
    "# print(file_path[path])\n",
    "\n",
    "# 결과 출력\n",
    "# for subject, data in file_path.items():\n",
    "#     print(f\"Subject: {subject}\")\n",
    "#     print(f\"  Videos: {data.get('video')}\")\n",
    "#     print(f\"  Ground Truth: {data.get('ground_truth')}\")\n",
    "#     print(f\"  BP: {data.get('BP')}\")\n",
    "\n",
    "# save_json(file_path, dataset_path_json_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIDEO -> NUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_yuv(rgb_image):\n",
    "    transformation_matrix = np.array([[0.299, 0.587, 0.114],\n",
    "                                      [-0.169, -0.331, 0.5],\n",
    "                                      [0.5, -0.419, -0.081]])\n",
    "    offset = np.array([0, 128, 128])\n",
    "    \n",
    "    yuv_image = np.dot(rgb_image, transformation_matrix.T) + offset\n",
    "    return yuv_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_normalize_data(data):\n",
    "    n, h, w, c = data.shape\n",
    "    diffnormalized_len = n - 1\n",
    "    diffnormalized_data = np.zeros((diffnormalized_len, h, w, c), dtype=np.float32)\n",
    "    diffnormalized_data_padding = np.zeros((1, h, w, c), dtype=np.float32)\n",
    "    \n",
    "    for j in range(diffnormalized_len):\n",
    "        diffnormalized_data[j, :, :, :] = (data[j + 1, :, :, :] - data[j, :, :, :]) / (data[j + 1, :, :, :] + data[j, :, :, :] + 1e-7)\n",
    "        \n",
    "    diffnormalized_data = diffnormalized_data / np.std(diffnormalized_data)\n",
    "    diffnormalized_data = np.append(diffnormalized_data, diffnormalized_data_padding, axis=0)\n",
    "    diffnormalized_data[np.isnan(diffnormalized_data)] = 0\n",
    "    \n",
    "    return diffnormalized_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self):\n",
    "        self.last_face_box_coor = None\n",
    "    \n",
    "    def detect_and_resize_face(self, image, frame_count, target_size=(128, 128), backend='HC', use_larger_box=False, larger_box_coef=2.0):\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "        global device_printed\n",
    "        \n",
    "        face_box_coor = None\n",
    "        \n",
    "        if device_printed:\n",
    "            print(f\"Using device: {device}\")\n",
    "            device_printed = False\n",
    "        \n",
    "        # HC 백엔드는 기존처럼 처리\n",
    "        if backend == \"HC\":\n",
    "            detector = cv2.CascadeClassifier('/home/neuroai/Downloads/ensenble/Ensemble/haarcascade_frontalface_default.xml')\n",
    "            face_zone = detector.detectMultiScale(image_rgb)\n",
    "\n",
    "            if len(face_zone) < 1:\n",
    "                return None\n",
    "            elif len(face_zone) >= 2:\n",
    "                max_width_index = np.argmax(face_zone[:, 2])\n",
    "                face_box_coor = face_zone[max_width_index]\n",
    "            else:\n",
    "                face_box_coor = face_zone[0]\n",
    "\n",
    "        # RF와 MT 백엔드는 frame_count에 따라 처리\n",
    "        elif backend == \"RF\" or backend == \"MT\":\n",
    "            if frame_count == 0 or frame_count % 160 == 0 or self.last_face_box_coor is None:\n",
    "                if backend == \"RF\":\n",
    "                    res = RetinaFace.detect_faces(image_rgb)\n",
    "\n",
    "                    if isinstance(res, dict) and len(res) > 0:\n",
    "                        highest_score_face = max(res.values(), key=lambda x: x['score'])\n",
    "                        face_zone = highest_score_face['facial_area']\n",
    "\n",
    "                        x_min, y_min, x_max, y_max = face_zone\n",
    "                        x = x_min\n",
    "                        y = y_min\n",
    "                        width = x_max - x_min\n",
    "                        height = y_max - y_min\n",
    "                        center_x = x + width // 2\n",
    "                        center_y = y + height // 2\n",
    "                        square_size = max(width, height)\n",
    "                        new_x = center_x - (square_size // 2)\n",
    "                        new_y = center_y - (square_size // 2)\n",
    "                        face_box_coor = [new_x, new_y, square_size, square_size]\n",
    "                    else:\n",
    "                        print(\"ERROR: No Face Detected - Using last detected face position\")\n",
    "                        face_box_coor = self.last_face_box_coor\n",
    "\n",
    "                elif backend == \"MT\":\n",
    "                    detector = MTCNN(keep_all=True, device=device)\n",
    "                    results = detector.detect_faces(image_rgb)\n",
    "                    if len(results) < 1:\n",
    "                        return None\n",
    "                    elif len(results) >= 2:\n",
    "                        max_width_index = np.argmax([r['box'][2] for r in results])\n",
    "                        face_box_coor = results[max_width_index]['box']\n",
    "                    else:\n",
    "                        face_box_coor = results[0]['box']\n",
    "\n",
    "                # 얼굴 위치를 저장\n",
    "                self.last_face_box_coor = face_box_coor\n",
    "            else:\n",
    "                # 이전에 검출된 얼굴 위치 사용\n",
    "                face_box_coor = self.last_face_box_coor\n",
    "\n",
    "        # 더 큰 박스를 사용할 경우\n",
    "        if use_larger_box:\n",
    "            face_box_coor[0] = max(0, face_box_coor[0] - (larger_box_coef - 1.0) / 2 * face_box_coor[2])\n",
    "            face_box_coor[1] = max(0, face_box_coor[1] - (larger_box_coef - 1.0) / 2 * face_box_coor[3])\n",
    "            face_box_coor[2] = int(larger_box_coef * face_box_coor[2])\n",
    "            face_box_coor[3] = int(larger_box_coef * face_box_coor[3])\n",
    "            \n",
    "        # 얼굴 크롭 및 리사이즈\n",
    "        x, y, w, h = face_box_coor\n",
    "        face_crop = image[int(y):int(y+h), int(x):int(x+w)]\n",
    "        resized_face = cv2.resize(face_crop, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        return resized_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_random_frames(face_frames, save_dir, subject_name, npy_index):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    num_frames = len(face_frames)\n",
    "    random_indices = random.sample(range(num_frames), min(1, num_frames))\n",
    "\n",
    "    for i in random_indices:\n",
    "        frame = face_frames[i]\n",
    "        # OpenCV는 BGR 형식을 사용하므로, RGB에서 BGR로 변환하여 저장해야 함\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        frame_file = os.path.join(save_dir, f\"{subject_name}_input{npy_index}_frame{i}.png\")\n",
    "        cv2.imwrite(frame_file, frame_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = FaceDetector()\n",
    "\n",
    "def process_video(video_path, output_dir, target_size=(128, 128), backend='HC', use_larger_box=False, larger_box_coef=1.0, chunk_size=160, start_idx=0, subject_name=\"subject\"):\n",
    "    rgb_output_dir = os.path.join(output_dir, \"RGB\")\n",
    "    yuv_output_dir = os.path.join(output_dir, \"YUV\")\n",
    "    image_save_dir = os.path.join(output_dir, \"Detect and crop and resize\")\n",
    "\n",
    "    if not os.path.exists(rgb_output_dir):\n",
    "        os.makedirs(rgb_output_dir)\n",
    "    if not os.path.exists(yuv_output_dir):\n",
    "        os.makedirs(yuv_output_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "    face_frames = []\n",
    "    rgb_files = []\n",
    "    yuv_files = []\n",
    "    npy_index = start_idx\n",
    "    \n",
    "    total_num = total_frames - (total_frames % 160)\n",
    "\n",
    "    with tqdm(total=total_num, desc=f\"Processing {subject_name}\", unit=\"frame\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            if total_frames - frame_count < chunk_size:\n",
    "                break\n",
    "\n",
    "            # Crop and resize the face, and update the progress bar\n",
    "            resized_face = face_detector.detect_and_resize_face(frame, frame_count, target_size, backend, use_larger_box, larger_box_coef )\n",
    "            #print(resized_face)\n",
    "            if resized_face is not None:\n",
    "                face_frames.append(resized_face)\n",
    "            else:\n",
    "                face_frames.append(np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8))\n",
    "            frame_count += 1\n",
    "\n",
    "            if frame_count % chunk_size == 0:\n",
    "                face_numpy = np.array(face_frames)\n",
    "                \n",
    "                face_frames_np = diff_normalize_data(face_numpy)\n",
    "                \n",
    "                # RGB npy 파일 저장\n",
    "                rgb_output_file = os.path.join(rgb_output_dir, f\"RGB_{subject_name}_input{npy_index}.npy\")\n",
    "                np.save(rgb_output_file, face_frames_np)\n",
    "                rgb_files.append(rgb_output_file)\n",
    "                \n",
    "                # YUV로 변환 후 npy 파일 저장\n",
    "                yuv_frames_np = rgb_to_yuv(face_frames_np)\n",
    "                yuv_output_file = os.path.join(yuv_output_dir, f\"YUV_{subject_name}_input{npy_index}.npy\")\n",
    "                np.save(yuv_output_file, yuv_frames_np)\n",
    "                yuv_files.append(yuv_output_file)\n",
    "                \n",
    "                # 랜덤 프레임을 이미지로 저장\n",
    "                save_random_frames(face_frames, image_save_dir, subject_name, npy_index)\n",
    "                \n",
    "                face_frames = []\n",
    "                npy_index += 1\n",
    "\n",
    "            pbar.update(1)  # Update progress bar after processing each frame\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return rgb_files, yuv_files, npy_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_subjects(data, output_dir, completed_file, subject_count=\"all\", reset=False, subject_name=None):\n",
    "    # 완료된 subject 목록을 로드 또는 초기화\n",
    "    if reset:\n",
    "        completed_subjects = []\n",
    "        save_completed_subjects(completed_subjects, completed_file)\n",
    "    else:\n",
    "        completed_subjects = load_completed_subjects(completed_file)\n",
    "    \n",
    "    processed_data = {}\n",
    "    \n",
    "    if subject_name:  # 특정 subject가 지정된 경우\n",
    "        subject_list = [subject_name]\n",
    "    else:\n",
    "        subject_list = list(data.keys())\n",
    "        if subject_count != \"all\":\n",
    "            subject_list = random.sample(subject_list, min(int(subject_count), len(subject_list)))\n",
    "\n",
    "    for subject in tqdm(subject_list, desc=\"Processing Subjects\"):\n",
    "        if subject in completed_subjects:\n",
    "            print(f\"Skipping already processed subject: {subject}\")\n",
    "            continue\n",
    "        \n",
    "        # 기존 코드로 subject 처리\n",
    "        details = data[subject]\n",
    "        video_paths = details['video']\n",
    "        BP = details['BP']\n",
    "        rgb_files = []\n",
    "        yuv_files = []\n",
    "        npy_index = 0\n",
    "\n",
    "        \n",
    "        #HC, RF, MT\n",
    "        for video_path in video_paths:\n",
    "            subject_output_dir = os.path.join(output_dir, subject)\n",
    "            rgb_npy_files, yuv_npy_files, npy_index = process_video(video_path, subject_output_dir, target_size=(128, 128), backend='RF', chunk_size=160, start_idx=npy_index, subject_name=subject)\n",
    "            rgb_files.extend(rgb_npy_files)\n",
    "            yuv_files.extend(yuv_npy_files)\n",
    "\n",
    "        processed_data[subject] = {\n",
    "            \"video_npy\": {\n",
    "                \"RGB\": rgb_files,\n",
    "                \"YUV\": yuv_files\n",
    "            },\n",
    "            \"BP\": BP\n",
    "        }\n",
    "\n",
    "        # 현재 subject 처리 완료 후 목록에 추가\n",
    "        completed_subjects.append(subject)\n",
    "        save_completed_subjects(completed_subjects, completed_file)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Subjects:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already processed subject: subject0\n",
      "Skipping already processed subject: subject1\n",
      "Skipping already processed subject: subject2\n",
      "Skipping already processed subject: subject3\n",
      "Skipping already processed subject: subject4\n",
      "Skipping already processed subject: subject5\n",
      "Skipping already processed subject: subject6\n",
      "Skipping already processed subject: subject7\n",
      "Skipping already processed subject: subject8\n",
      "Skipping already processed subject: subject9\n",
      "Skipping already processed subject: subject10\n",
      "Skipping already processed subject: subject11\n",
      "Skipping already processed subject: subject12\n",
      "Skipping already processed subject: subject13\n",
      "Skipping already processed subject: subject14\n",
      "Skipping already processed subject: subject15\n",
      "Skipping already processed subject: subject16\n",
      "Skipping already processed subject: subject17\n",
      "Skipping already processed subject: subject18\n",
      "Skipping already processed subject: subject19\n",
      "Skipping already processed subject: subject20\n",
      "Skipping already processed subject: subject21\n",
      "Skipping already processed subject: subject22\n",
      "Skipping already processed subject: subject23\n",
      "Skipping already processed subject: subject24\n",
      "Skipping already processed subject: subject25\n",
      "Skipping already processed subject: subject26\n",
      "Skipping already processed subject: subject27\n",
      "Skipping already processed subject: subject28\n",
      "Skipping already processed subject: subject29\n",
      "Skipping already processed subject: subject30\n",
      "Skipping already processed subject: subject31\n",
      "Skipping already processed subject: subject32\n",
      "Skipping already processed subject: subject33\n",
      "Skipping already processed subject: subject34\n",
      "Skipping already processed subject: subject35\n",
      "Skipping already processed subject: subject36\n",
      "Skipping already processed subject: subject37\n",
      "Skipping already processed subject: subject38\n",
      "Skipping already processed subject: subject39\n",
      "Skipping already processed subject: subject40\n",
      "Skipping already processed subject: subject41\n",
      "Skipping already processed subject: subject42\n",
      "Skipping already processed subject: subject43\n",
      "Skipping already processed subject: subject44\n",
      "Skipping already processed subject: subject45\n",
      "Skipping already processed subject: subject46\n",
      "Skipping already processed subject: subject47\n",
      "Skipping already processed subject: subject48\n",
      "Skipping already processed subject: subject49\n",
      "Skipping already processed subject: subject50\n",
      "Skipping already processed subject: subject51\n",
      "Skipping already processed subject: subject52\n",
      "Skipping already processed subject: subject53\n",
      "Skipping already processed subject: subject54\n",
      "Skipping already processed subject: subject55\n",
      "Skipping already processed subject: subject56\n",
      "Skipping already processed subject: subject57\n",
      "Skipping already processed subject: subject58\n",
      "Skipping already processed subject: subject59\n",
      "Skipping already processed subject: subject60\n",
      "Skipping already processed subject: subject61\n",
      "Skipping already processed subject: subject62\n",
      "Skipping already processed subject: subject63\n",
      "Skipping already processed subject: subject64\n",
      "Skipping already processed subject: subject65\n",
      "Skipping already processed subject: subject66\n",
      "Skipping already processed subject: subject67\n",
      "Skipping already processed subject: subject68\n",
      "Skipping already processed subject: subject69\n",
      "Skipping already processed subject: subject70\n",
      "Skipping already processed subject: subject71\n",
      "Skipping already processed subject: subject72\n",
      "Skipping already processed subject: subject73\n",
      "Skipping already processed subject: subject74\n",
      "Skipping already processed subject: subject75\n",
      "Skipping already processed subject: subject76\n",
      "Skipping already processed subject: subject77\n",
      "Skipping already processed subject: subject78\n",
      "Skipping already processed subject: subject79\n",
      "Skipping already processed subject: subject80\n",
      "Skipping already processed subject: subject81\n",
      "Skipping already processed subject: subject82\n",
      "Skipping already processed subject: subject83\n",
      "Skipping already processed subject: subject84\n",
      "Skipping already processed subject: subject85\n",
      "Skipping already processed subject: subject86\n",
      "Skipping already processed subject: subject87\n",
      "Skipping already processed subject: subject88\n",
      "Skipping already processed subject: subject89\n",
      "Skipping already processed subject: subject90\n",
      "Skipping already processed subject: subject91\n",
      "Skipping already processed subject: subject92\n",
      "Skipping already processed subject: subject93\n",
      "Skipping already processed subject: subject94\n",
      "Skipping already processed subject: subject95\n",
      "Skipping already processed subject: subject96\n",
      "Skipping already processed subject: subject97\n",
      "Skipping already processed subject: subject98\n",
      "Skipping already processed subject: subject99\n",
      "Skipping already processed subject: subject100\n",
      "Skipping already processed subject: subject101\n",
      "Skipping already processed subject: subject102\n",
      "Skipping already processed subject: subject103\n",
      "Skipping already processed subject: subject104\n",
      "Skipping already processed subject: subject105\n",
      "Skipping already processed subject: subject106\n",
      "Skipping already processed subject: subject107\n",
      "Skipping already processed subject: subject108\n",
      "Skipping already processed subject: subject109\n",
      "Skipping already processed subject: subject110\n",
      "Skipping already processed subject: subject111\n",
      "Skipping already processed subject: subject112\n",
      "Skipping already processed subject: subject113\n",
      "Skipping already processed subject: subject114\n",
      "Skipping already processed subject: subject115\n",
      "Skipping already processed subject: subject116\n",
      "Skipping already processed subject: subject117\n",
      "Skipping already processed subject: subject118\n",
      "Skipping already processed subject: subject119\n",
      "Skipping already processed subject: subject120\n",
      "Skipping already processed subject: subject121\n",
      "Skipping already processed subject: subject122\n",
      "Skipping already processed subject: subject123\n",
      "Skipping already processed subject: subject124\n",
      "Skipping already processed subject: subject125\n",
      "Skipping already processed subject: subject126\n",
      "Skipping already processed subject: subject127\n",
      "Skipping already processed subject: subject128\n",
      "Skipping already processed subject: subject129\n",
      "Skipping already processed subject: subject130\n",
      "Skipping already processed subject: subject131\n",
      "Skipping already processed subject: subject132\n",
      "Skipping already processed subject: subject133\n",
      "Skipping already processed subject: subject134\n",
      "Skipping already processed subject: subject135\n",
      "Skipping already processed subject: subject136\n",
      "Skipping already processed subject: subject137\n",
      "Skipping already processed subject: subject138\n",
      "Skipping already processed subject: subject139\n",
      "Skipping already processed subject: subject140\n",
      "Skipping already processed subject: subject141\n",
      "Skipping already processed subject: subject142\n",
      "Skipping already processed subject: subject143\n",
      "Skipping already processed subject: subject144\n",
      "Skipping already processed subject: subject145\n",
      "Skipping already processed subject: subject146\n",
      "Skipping already processed subject: subject147\n",
      "Skipping already processed subject: subject148\n",
      "Skipping already processed subject: subject149\n",
      "Skipping already processed subject: subject150\n",
      "Skipping already processed subject: subject151\n",
      "Skipping already processed subject: subject152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subject153:  93%|█████████▎| 741/800 [00:19<00:01, 37.29frame/s]\n",
      "Processing subject153:  93%|█████████▎| 741/800 [00:20<00:01, 36.78frame/s]\n",
      "Processing subject154:  93%|█████████▎| 741/800 [00:19<00:01, 38.00frame/s]\n",
      "Processing subject154:  93%|█████████▎| 741/800 [00:19<00:01, 37.61frame/s]\n",
      "Processing subject155:  93%|█████████▎| 741/800 [00:19<00:01, 37.74frame/s]\n",
      "Processing subject155:  93%|█████████▎| 741/800 [00:20<00:01, 37.03frame/s]\n",
      "Processing subject156:  93%|█████████▎| 741/800 [00:19<00:01, 37.43frame/s]\n",
      "Processing subject156:  93%|█████████▎| 741/800 [00:19<00:01, 37.69frame/s]\n",
      "Processing subject157:  93%|█████████▎| 741/800 [00:19<00:01, 38.81frame/s]\n",
      "[h264 @ 0xd5a1d80] Reference 2 >= 2\n",
      "[h264 @ 0xd5a1d80] error while decoding MB 59 1, bytestream 2297434\n",
      "Processing subject157:  93%|█████████▎| 741/800 [00:19<00:01, 38.81frame/s]\n",
      "Processing Subjects:  63%|██████▎   | 158/250 [03:19<04:16,  2.79s/it][h264 @ 0xd5a92c0] gray chroma\n",
      "[h264 @ 0xd5a92c0] error while decoding MB 70 37, bytestream 1095675\n",
      "[h264 @ 0xd5a92c0] left block unavailable for requested intra mode\n",
      "[h264 @ 0xd5a92c0] error while decoding MB 0 72, bytestream 87289\n",
      "Processing subject158:  93%|█████████▎| 741/800 [00:19<00:01, 38.92frame/s]\n",
      "Processing subject158:  93%|█████████▎| 741/800 [00:19<00:01, 37.84frame/s]\n",
      "Processing subject159:  93%|█████████▎| 741/800 [00:19<00:01, 38.02frame/s]\n",
      "Processing subject159:  93%|█████████▎| 741/800 [00:19<00:01, 37.93frame/s]\n",
      "Processing subject160:  93%|█████████▎| 741/800 [00:19<00:01, 37.39frame/s]\n",
      "Processing subject160:  93%|█████████▎| 741/800 [00:19<00:01, 37.13frame/s]\n",
      "Processing subject161:  93%|█████████▎| 741/800 [00:19<00:01, 38.13frame/s]\n",
      "Processing subject161:  93%|█████████▎| 741/800 [00:18<00:01, 39.07frame/s]\n",
      "Processing subject162:  93%|█████████▎| 741/800 [00:17<00:01, 41.77frame/s]\n",
      "Processing subject162:  93%|█████████▎| 741/800 [00:17<00:01, 41.47frame/s]\n",
      "Processing subject163:  93%|█████████▎| 741/800 [00:19<00:01, 37.40frame/s]\n",
      "Processing subject163:  93%|█████████▎| 741/800 [00:19<00:01, 37.46frame/s]\n",
      "Processing subject164:  93%|█████████▎| 741/800 [00:19<00:01, 38.38frame/s]\n",
      "Processing subject164:  93%|█████████▎| 741/800 [00:19<00:01, 38.67frame/s]\n",
      "Processing subject165:  93%|█████████▎| 741/800 [00:19<00:01, 37.73frame/s]\n",
      "Processing subject165:  93%|█████████▎| 741/800 [00:19<00:01, 37.34frame/s]\n",
      "Processing subject166:  93%|█████████▎| 741/800 [00:19<00:01, 38.72frame/s]\n",
      "[h264 @ 0xf1387c0] left block unavailable for requested intra4x4 mode -1\n",
      "[h264 @ 0xf1387c0] error while decoding MB 0 70, bytestream 247577\n",
      "Processing subject166:  93%|█████████▎| 741/800 [00:19<00:01, 38.61frame/s]\n",
      "Processing subject167:  93%|█████████▎| 741/800 [00:18<00:01, 39.14frame/s]\n",
      "[h264 @ 0xea74a00] gray chroma\n",
      "[h264 @ 0xea74a00] error while decoding MB 86 62, bytestream 408647\n",
      "Processing subject167:  93%|█████████▎| 741/800 [00:18<00:01, 39.14frame/s]\n",
      "Processing subject168:  93%|█████████▎| 741/800 [00:19<00:01, 38.90frame/s]\n",
      "Processing subject168:  93%|█████████▎| 741/800 [00:19<00:01, 38.37frame/s]\n",
      "Processing subject169:  93%|█████████▎| 741/800 [00:19<00:01, 38.16frame/s]\n",
      "Processing subject169:  93%|█████████▎| 741/800 [00:19<00:01, 38.19frame/s]\n",
      "Processing subject170:  93%|█████████▎| 741/800 [00:18<00:01, 41.12frame/s]\n",
      "Processing subject170:  93%|█████████▎| 741/800 [00:17<00:01, 41.23frame/s]\n",
      "Processing subject171:  93%|█████████▎| 741/800 [00:18<00:01, 39.35frame/s]\n",
      "Processing subject171:  93%|█████████▎| 741/800 [00:18<00:01, 40.08frame/s]\n",
      "Processing subject172:  93%|█████████▎| 741/800 [00:19<00:01, 37.83frame/s]\n",
      "Processing subject172:  93%|█████████▎| 741/800 [00:19<00:01, 38.21frame/s]\n",
      "Processing subject173:  93%|█████████▎| 741/800 [00:18<00:01, 39.54frame/s]\n",
      "Processing subject173:  93%|█████████▎| 741/800 [00:18<00:01, 40.02frame/s]\n",
      "Processing subject174:  93%|█████████▎| 741/800 [00:18<00:01, 39.25frame/s]\n",
      "Processing subject174:  93%|█████████▎| 741/800 [00:19<00:01, 38.66frame/s]\n",
      "Processing subject175:  93%|█████████▎| 741/800 [00:20<00:01, 36.75frame/s]\n",
      "Processing subject175:  93%|█████████▎| 741/800 [00:20<00:01, 36.54frame/s]\n",
      "Processing subject176:  93%|█████████▎| 741/800 [00:19<00:01, 38.53frame/s]\n",
      "Processing subject176:  93%|█████████▎| 741/800 [00:19<00:01, 38.99frame/s]\n",
      "Processing Subjects:  71%|███████   | 177/250 [15:40<47:10, 38.78s/it][h264 @ 0xeb305c0] Reference 5 >= 2\n",
      "[h264 @ 0xeb305c0] error while decoding MB 38 57, bytestream 599279\n",
      "Processing subject177:  93%|█████████▎| 741/800 [00:19<00:01, 38.86frame/s]\n",
      "Processing subject177:  93%|█████████▎| 741/800 [00:19<00:01, 38.43frame/s]\n",
      "Processing subject178:  93%|█████████▎| 741/800 [00:17<00:01, 42.44frame/s]\n",
      "Processing subject178:  93%|█████████▎| 741/800 [00:14<00:01, 50.12frame/s]\n",
      "Processing subject179:  93%|█████████▎| 741/800 [00:18<00:01, 39.63frame/s]\n",
      "Processing subject179:  93%|█████████▎| 741/800 [00:18<00:01, 39.59frame/s]\n",
      "Processing subject180:  93%|█████████▎| 741/800 [00:18<00:01, 40.86frame/s]\n",
      "Processing subject180:  93%|█████████▎| 741/800 [00:17<00:01, 41.53frame/s]\n",
      "Processing subject181:  93%|█████████▎| 741/800 [00:19<00:01, 37.84frame/s]\n",
      "Processing subject181:  93%|█████████▎| 741/800 [00:19<00:01, 38.50frame/s]\n",
      "Processing subject182:  93%|█████████▎| 741/800 [00:19<00:01, 37.96frame/s]\n",
      "[h264 @ 0xe430f00] gray chroma\n",
      "[h264 @ 0xe430f00] error while decoding MB 20 47, bytestream 947979\n",
      "Processing subject182:  93%|█████████▎| 741/800 [00:19<00:01, 37.79frame/s]\n",
      "Processing subject183:  93%|█████████▎| 741/800 [00:19<00:01, 38.83frame/s]\n",
      "Processing subject183:  93%|█████████▎| 741/800 [00:19<00:01, 38.82frame/s]\n",
      "Processing subject184:  93%|█████████▎| 741/800 [00:19<00:01, 38.41frame/s]\n",
      "[h264 @ 0xd55edc0] left block unavailable for requested intra4x4 mode -1\n",
      "[h264 @ 0xd55edc0] error while decoding MB 0 17, bytestream 1700114\n",
      "Processing subject184:  93%|█████████▎| 741/800 [00:19<00:01, 38.25frame/s]\n",
      "Processing subject185:  93%|█████████▎| 741/800 [00:19<00:01, 38.06frame/s]\n",
      "Processing subject185:  93%|█████████▎| 741/800 [00:18<00:01, 39.03frame/s]\n",
      "Processing subject186:  93%|█████████▎| 741/800 [00:19<00:01, 37.77frame/s]\n",
      "Processing subject186:  93%|█████████▎| 741/800 [00:19<00:01, 37.80frame/s]\n",
      "Processing subject187:  93%|█████████▎| 741/800 [00:18<00:01, 40.11frame/s]\n",
      "Processing subject187:  93%|█████████▎| 741/800 [00:18<00:01, 39.39frame/s]\n",
      "Processing subject188:  93%|█████████▎| 741/800 [00:19<00:01, 38.66frame/s]\n",
      "Processing subject188:  93%|█████████▎| 741/800 [00:19<00:01, 38.92frame/s]\n",
      "Processing subject189:  93%|█████████▎| 741/800 [00:19<00:01, 38.82frame/s]\n",
      "Processing subject189:  93%|█████████▎| 741/800 [00:19<00:01, 38.55frame/s]\n",
      "Processing subject190:  93%|█████████▎| 741/800 [00:19<00:01, 37.57frame/s]\n",
      "Processing subject190:  93%|█████████▎| 741/800 [00:19<00:01, 38.04frame/s]\n",
      "Processing subject191:  93%|█████████▎| 741/800 [00:19<00:01, 37.69frame/s]\n",
      "Processing subject191:  93%|█████████▎| 741/800 [00:19<00:01, 37.74frame/s]\n",
      "Processing Subjects:  77%|███████▋  | 192/250 [25:19<38:06, 39.43s/it][h264 @ 0xea55fc0] Reference 2 >= 2\n",
      "[h264 @ 0xea55fc0] error while decoding MB 65 14, bytestream 1619696\n",
      "Processing subject192:  93%|█████████▎| 741/800 [00:18<00:01, 39.56frame/s]\n",
      "Processing subject192:  93%|█████████▎| 741/800 [00:18<00:01, 40.24frame/s]\n",
      "Processing subject193:  93%|█████████▎| 741/800 [00:19<00:01, 37.05frame/s]\n",
      "Processing subject193:  93%|█████████▎| 741/800 [00:19<00:01, 37.46frame/s]\n",
      "Processing subject194:  93%|█████████▎| 741/800 [00:19<00:01, 38.83frame/s]\n",
      "Processing subject194:  93%|█████████▎| 741/800 [00:18<00:01, 39.24frame/s]\n",
      "Processing subject195:  93%|█████████▎| 741/800 [00:18<00:01, 39.09frame/s]\n",
      "Processing subject195:  93%|█████████▎| 741/800 [00:18<00:01, 39.19frame/s]\n",
      "Processing subject196:  93%|█████████▎| 741/800 [00:19<00:01, 38.05frame/s]\n",
      "[h264 @ 0xde7da80] gray chroma\n",
      "[h264 @ 0xde7da80] error while decoding MB 24 70, bytestream 166282\n",
      "Processing subject196:  93%|█████████▎| 741/800 [00:19<00:01, 37.99frame/s]\n",
      "Processing subject197:  93%|█████████▎| 741/800 [00:19<00:01, 38.49frame/s]\n",
      "Processing subject197:  93%|█████████▎| 741/800 [00:19<00:01, 37.95frame/s]\n",
      "Processing subject198:  93%|█████████▎| 741/800 [00:18<00:01, 39.82frame/s]\n",
      "Processing subject198:  93%|█████████▎| 741/800 [00:18<00:01, 39.85frame/s]\n",
      "Processing subject199:  93%|█████████▎| 741/800 [00:19<00:01, 38.42frame/s]\n",
      "Processing subject199:  93%|█████████▎| 741/800 [00:19<00:01, 38.24frame/s]\n",
      "Processing subject200:  93%|█████████▎| 741/800 [00:18<00:01, 39.09frame/s]\n",
      "Processing subject200:  93%|█████████▎| 741/800 [00:19<00:01, 38.51frame/s]\n",
      "Processing subject201:  93%|█████████▎| 741/800 [00:19<00:01, 38.46frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No Face Detected - Using last detected face position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0xf157b40] Reference 3 >= 2\n",
      "[h264 @ 0xf157b40] error while decoding MB 54 71, bytestream 183790\n",
      "Processing subject201:  93%|█████████▎| 741/800 [00:19<00:01, 38.29frame/s]\n",
      "Processing subject202:  93%|█████████▎| 741/800 [00:19<00:01, 38.12frame/s]\n",
      "[h264 @ 0xdeaa180] gray chroma\n",
      "[h264 @ 0xdeaa180] error while decoding MB 60 39, bytestream 1057703\n",
      "Processing subject202:  93%|█████████▎| 741/800 [00:19<00:01, 37.54frame/s]\n",
      "Processing subject203:  93%|█████████▎| 741/800 [00:17<00:01, 41.71frame/s]\n",
      "Processing subject203:  93%|█████████▎| 741/800 [00:17<00:01, 42.24frame/s]\n",
      "Processing subject204:  93%|█████████▎| 741/800 [00:19<00:01, 38.43frame/s]\n",
      "Processing subject204:  93%|█████████▎| 741/800 [00:19<00:01, 38.43frame/s]\n",
      "Processing subject205:  93%|█████████▎| 741/800 [00:18<00:01, 40.65frame/s]\n",
      "Processing subject205:  93%|█████████▎| 741/800 [00:18<00:01, 39.66frame/s]\n",
      "Processing subject206:  93%|█████████▎| 741/800 [00:19<00:01, 37.77frame/s]\n",
      "[h264 @ 0x1a257c40] gray chroma\n",
      "[h264 @ 0x1a257c40] error while decoding MB 50 54, bytestream 610549\n",
      "Processing subject206:  93%|█████████▎| 741/800 [00:19<00:01, 38.17frame/s]\n",
      "Processing subject207:  93%|█████████▎| 741/800 [00:19<00:01, 37.58frame/s]\n",
      "Processing subject207:  93%|█████████▎| 741/800 [00:20<00:01, 36.91frame/s]\n",
      "Processing subject208:  93%|█████████▎| 741/800 [00:20<00:01, 36.90frame/s]\n",
      "Processing subject208:  93%|█████████▎| 741/800 [00:20<00:01, 36.56frame/s]\n",
      "Processing subject209:  93%|█████████▎| 741/800 [00:19<00:01, 38.22frame/s]\n",
      "Processing subject209:  93%|█████████▎| 741/800 [00:19<00:01, 38.03frame/s]\n",
      "Processing subject210:  93%|█████████▎| 741/800 [00:18<00:01, 39.06frame/s]\n",
      "Processing subject210:  93%|█████████▎| 741/800 [00:18<00:01, 39.67frame/s]\n",
      "Processing Subjects:  84%|████████▍ | 211/250 [37:40<25:31, 39.27s/it][h264 @ 0xee19580] Reference 3 >= 2\n",
      "[h264 @ 0xee19580] error while decoding MB 119 15, bytestream 1818979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No Face Detected - Using last detected face position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subject211:  93%|█████████▎| 741/800 [00:19<00:01, 38.78frame/s]\n",
      "Processing subject211:  93%|█████████▎| 741/800 [00:18<00:01, 39.22frame/s]\n",
      "Processing subject212:  93%|█████████▎| 741/800 [00:18<00:01, 39.09frame/s]\n",
      "Processing subject212:  93%|█████████▎| 741/800 [00:18<00:01, 39.29frame/s]\n",
      "Processing subject213:  93%|█████████▎| 741/800 [00:19<00:01, 38.75frame/s]\n",
      "Processing subject213:  93%|█████████▎| 741/800 [00:19<00:01, 38.82frame/s]\n",
      "Processing subject214:  93%|█████████▎| 741/800 [00:20<00:01, 37.04frame/s]\n",
      "Processing subject214:  93%|█████████▎| 741/800 [00:19<00:01, 37.35frame/s]\n",
      "Processing subject215:  93%|█████████▎| 741/800 [00:19<00:01, 37.75frame/s]\n",
      "Processing subject215:  93%|█████████▎| 741/800 [00:19<00:01, 37.75frame/s]\n",
      "Processing subject216:  93%|█████████▎| 741/800 [00:18<00:01, 39.13frame/s]\n",
      "Processing subject216:  93%|█████████▎| 741/800 [00:18<00:01, 39.40frame/s]\n",
      "Processing subject217:  93%|█████████▎| 741/800 [00:19<00:01, 37.07frame/s]\n",
      "Processing subject217:  93%|█████████▎| 741/800 [00:19<00:01, 37.80frame/s]\n",
      "Processing subject218:  93%|█████████▎| 741/800 [00:19<00:01, 37.48frame/s]\n",
      "[h264 @ 0x12a2a640] gray chroma\n",
      "[h264 @ 0x12a2a640] error while decoding MB 72 70, bytestream 118556\n",
      "Processing subject218:  93%|█████████▎| 741/800 [00:19<00:01, 38.50frame/s]\n",
      "Processing subject219:  93%|█████████▎| 741/800 [00:18<00:01, 39.41frame/s]\n",
      "Processing subject219:  93%|█████████▎| 741/800 [00:18<00:01, 39.57frame/s]\n",
      "Processing subject220:  93%|█████████▎| 741/800 [00:20<00:01, 36.71frame/s]\n",
      "Processing subject220:  93%|█████████▎| 741/800 [00:20<00:01, 36.86frame/s]\n",
      "Processing subject221:  93%|█████████▎| 741/800 [00:19<00:01, 38.41frame/s]\n",
      "Processing subject221:  93%|█████████▎| 741/800 [00:19<00:01, 38.20frame/s]\n",
      "Processing subject222:  93%|█████████▎| 741/800 [00:18<00:01, 39.53frame/s]\n",
      "Processing subject222:  93%|█████████▎| 741/800 [00:19<00:01, 38.99frame/s]\n",
      "Processing subject223:  93%|█████████▎| 741/800 [00:18<00:01, 39.03frame/s]\n",
      "Processing subject223:  93%|█████████▎| 741/800 [00:19<00:01, 37.55frame/s]\n",
      "Processing Subjects:  90%|████████▉ | 224/250 [46:11<17:00, 39.27s/it][h264 @ 0x126a4440] gray chroma\n",
      "[h264 @ 0x126a4440] error while decoding MB 105 39, bytestream 1125393\n",
      "Processing subject224:  93%|█████████▎| 741/800 [00:18<00:01, 39.04frame/s]\n",
      "[h264 @ 0xd3a4c40] Reference 2 >= 2\n",
      "[h264 @ 0xd3a4c40] error while decoding MB 88 1, bytestream 2129412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No Face Detected - Using last detected face position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subject224:  93%|█████████▎| 741/800 [00:18<00:01, 39.70frame/s]\n",
      "Processing subject225:  93%|█████████▎| 741/800 [00:19<00:01, 38.76frame/s]\n",
      "Processing subject225:  93%|█████████▎| 741/800 [00:19<00:01, 38.06frame/s]\n",
      "Processing subject226:  93%|█████████▎| 741/800 [00:19<00:01, 37.88frame/s]\n",
      "Processing subject226:  93%|█████████▎| 741/800 [00:19<00:01, 37.56frame/s]\n",
      "Processing subject227:  93%|█████████▎| 741/800 [00:19<00:01, 38.51frame/s]\n",
      "Processing subject227:  93%|█████████▎| 741/800 [00:18<00:01, 39.15frame/s]\n",
      "Processing subject228:  93%|█████████▎| 741/800 [00:16<00:01, 44.99frame/s]\n",
      "Processing subject228:  93%|█████████▎| 741/800 [00:16<00:01, 45.73frame/s]\n",
      "Processing subject229:  93%|█████████▎| 741/800 [00:18<00:01, 40.34frame/s]\n",
      "Processing subject229:  93%|█████████▎| 741/800 [00:18<00:01, 40.18frame/s]\n",
      "Processing subject230:  93%|█████████▎| 741/800 [00:19<00:01, 38.19frame/s]\n",
      "Processing subject230:  93%|█████████▎| 741/800 [00:19<00:01, 37.87frame/s]\n",
      "Processing subject231:  93%|█████████▎| 741/800 [00:18<00:01, 39.13frame/s]\n",
      "Processing subject231:  93%|█████████▎| 741/800 [00:19<00:01, 39.00frame/s]\n",
      "Processing subject232:  93%|█████████▎| 741/800 [00:17<00:01, 43.43frame/s]\n",
      "Processing subject232:  93%|█████████▎| 741/800 [00:15<00:01, 48.98frame/s]\n",
      "Processing Subjects:  93%|█████████▎| 233/250 [51:49<10:20, 36.50s/it][h264 @ 0xf055140] gray chroma\n",
      "[h264 @ 0xf055140] error while decoding MB 97 40, bytestream 1191338\n",
      "Processing subject233:  93%|█████████▎| 741/800 [00:20<00:01, 36.33frame/s]\n",
      "Processing subject233:  93%|█████████▎| 741/800 [00:20<00:01, 36.15frame/s]\n",
      "Processing subject234:  93%|█████████▎| 741/800 [00:19<00:01, 38.05frame/s]\n",
      "Processing subject234:  93%|█████████▎| 741/800 [00:19<00:01, 37.77frame/s]\n",
      "Processing subject235:  93%|█████████▎| 741/800 [00:19<00:01, 38.40frame/s]\n",
      "Processing subject235:  93%|█████████▎| 741/800 [00:19<00:01, 37.86frame/s]\n",
      "Processing subject236:  93%|█████████▎| 741/800 [00:18<00:01, 39.49frame/s]\n",
      "Processing subject236:  93%|█████████▎| 741/800 [00:19<00:01, 38.01frame/s]\n",
      "Processing subject237:  93%|█████████▎| 741/800 [00:19<00:01, 37.50frame/s]\n"
     ]
    }
   ],
   "source": [
    "subject_count = \"all\"  # \"all\" 또는 처리할 subject 수\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open(dataset_path_json_save_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 모든 subject에 대해 비디오 처리\n",
    "processed_data = process_all_subjects(data, processed_numpy_save_path, completed_file= processing_save_list_path, subject_count=subject_count, reset=False, subject_name=None)\n",
    "\n",
    "# 결과를 JSON 파일로 저장\n",
    "save_to_json(processed_data, vital_video_list_path)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {vital_video_list_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
